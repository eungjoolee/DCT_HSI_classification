Computation on CUDA GPU device 0
Split 200 bands into 4 groups and use 2 frequency
Apply KD...
Split 200 bands into 4 groups and use 50 frequency
Image has dimensions 145x145 and 8 channels
Image has dimensions 145x145 and 200 channels
Using existing train/test split...
7374 samples selected (over 10249)
Running an experiment with the he_customized model run 1/1
Using existing train/val split...
{'dataset': 'IndianPines', 'model': 'he_customized', 'folder': './Datasets/', 'cuda': 0, 'runs': 1, 'training_sample': 0.8, 'sampling_mode': 'fixed', 'train_set': './Datasets/IndianPines/train.mat', 'test_set': './Datasets/IndianPines/test.mat', 'val_set': './Datasets/IndianPines/val.mat', 'epoch': 100, 'lr': 0.01, 'class_balancing': False, 'test_stride': 1, 'flip_augmentation': True, 'radiation_augmentation': False, 'mixture_augmentation': False, 'with_exploration': False, 'band_group': 4, 'use_freq': 2, 'use_kernel': 16, 'band_selection': 0, 'selection_mode': 'random', 't_band_group': 4, 't_use_freq': 50, 't_use_kernel': 16, 't_restore': './checkpoints/he_et_al_customized/IndianPines/teacher/2021-04-17_02:09:25.519213_epoch100_0.90_gp_4_fq_50_ch_16.pth', 'kd_alpha': 0.9, 'kd_temp': 20.0, 'n_classes': 17, 'n_bands': 8, 'ignored_labels': [0], 'device': device(type='cuda', index=0), 'n_kernel': 16, 't_n_bands': 200, 'weights': tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
       device='cuda:0'), 'patch_size': 7, 'batch_size': 40, 'learning_rate': 0.01, 'scheduler': <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f961014f910>, 'supervision': 'full', 'center_pixel': True}
Network :
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv3d: 1-1                            [-1, 16, 103, 5, 5]       736
├─Conv3d: 1-2                            [-1, 16, 103, 5, 5]       272
├─Conv3d: 1-3                            [-1, 16, 103, 5, 5]       784
├─Conv3d: 1-4                            [-1, 16, 103, 5, 5]       784
├─Conv3d: 1-5                            [-1, 16, 103, 5, 5]       784
├─Conv3d: 1-6                            [-1, 16, 103, 5, 5]       272
├─Conv3d: 1-7                            [-1, 16, 103, 5, 5]       784
├─Conv3d: 1-8                            [-1, 16, 103, 5, 5]       784
├─Conv3d: 1-9                            [-1, 16, 103, 5, 5]       784
├─Conv3d: 1-10                           [-1, 16, 101, 4, 4]       3,088
├─Dropout: 1-11                          [-1, 256]                 --
├─Linear: 1-12                           [-1, 17]                  4,369
==========================================================================================
Total params: 13,441
Trainable params: 13,441
Non-trainable params: 0
Total mult-adds (M): 20.01
==========================================================================================
Input size (MB): 0.04
Forward/backward pass size (MB): 3.03
Params size (MB): 0.05
Estimated Total Size (MB): 3.12
==========================================================================================
Train (epoch 1/100) [3960/7120 (56%)]	Loss: 1.031818
Train (epoch 2/100) [840/7120 (12%)]	Loss: 0.765390
Train (epoch 2/100) [4840/7120 (68%)]	Loss: 0.746400
Train (epoch 3/100) [1720/7120 (24%)]	Loss: 0.693509
Train (epoch 3/100) [5720/7120 (80%)]	Loss: 0.681409
Train (epoch 4/100) [2600/7120 (37%)]	Loss: 0.659205
Train (epoch 4/100) [6600/7120 (93%)]	Loss: 0.658126
Train (epoch 5/100) [3480/7120 (49%)]	Loss: 0.631437
Train (epoch 6/100) [360/7120 (5%)]	Loss: 0.640094
Train (epoch 6/100) [4360/7120 (61%)]	Loss: 0.640733
Train (epoch 7/100) [1240/7120 (17%)]	Loss: 0.599521
Train (epoch 7/100) [5240/7120 (74%)]	Loss: 0.612532
Train (epoch 8/100) [2120/7120 (30%)]	Loss: 0.621232
Train (epoch 8/100) [6120/7120 (86%)]	Loss: 0.596616
Train (epoch 9/100) [3000/7120 (42%)]	Loss: 0.603948
Train (epoch 9/100) [7000/7120 (98%)]	Loss: 0.590597
Train (epoch 10/100) [3880/7120 (54%)]	Loss: 0.594642
Train (epoch 11/100) [760/7120 (11%)]	Loss: 0.579803
Train (epoch 11/100) [4760/7120 (67%)]	Loss: 0.582458
Train (epoch 12/100) [1640/7120 (23%)]	Loss: 0.575907
Train (epoch 12/100) [5640/7120 (79%)]	Loss: 0.574462
Train (epoch 13/100) [2520/7120 (35%)]	Loss: 0.577428
Train (epoch 13/100) [6520/7120 (92%)]	Loss: 0.567570
Train (epoch 14/100) [3400/7120 (48%)]	Loss: 0.555732
Train (epoch 15/100) [280/7120 (4%)]	Loss: 0.549050
Train (epoch 15/100) [4280/7120 (60%)]	Loss: 0.559085
Train (epoch 16/100) [1160/7120 (16%)]	Loss: 0.547716
Train (epoch 16/100) [5160/7120 (72%)]	Loss: 0.538074
Train (epoch 17/100) [2040/7120 (29%)]	Loss: 0.539314
Train (epoch 17/100) [6040/7120 (85%)]	Loss: 0.532104
Train (epoch 18/100) [2920/7120 (41%)]	Loss: 0.532617
Train (epoch 18/100) [6920/7120 (97%)]	Loss: 0.518390
Train (epoch 19/100) [3800/7120 (53%)]	Loss: 0.513938
Train (epoch 20/100) [680/7120 (10%)]	Loss: 0.513625
Train (epoch 20/100) [4680/7120 (66%)]	Loss: 0.507367
Saving neural network weights in 2021-04-17 16:03:42.564934_epoch20_0.51_gp_4_fq_2_ch_16
Train (epoch 21/100) [1560/7120 (22%)]	Loss: 0.504959
Train (epoch 21/100) [5560/7120 (78%)]	Loss: 0.505711
Train (epoch 22/100) [2440/7120 (34%)]	Loss: 0.501791
Train (epoch 22/100) [6440/7120 (90%)]	Loss: 0.490227
Train (epoch 23/100) [3320/7120 (47%)]	Loss: 0.486784
Train (epoch 24/100) [200/7120 (3%)]	Loss: 0.488422
Train (epoch 24/100) [4200/7120 (59%)]	Loss: 0.475647
Train (epoch 25/100) [1080/7120 (15%)]	Loss: 0.477267
Train (epoch 25/100) [5080/7120 (71%)]	Loss: 0.475139
Train (epoch 26/100) [1960/7120 (28%)]	Loss: 0.461912
Train (epoch 26/100) [5960/7120 (84%)]	Loss: 0.466255
Train (epoch 27/100) [2840/7120 (40%)]	Loss: 0.461748
Train (epoch 27/100) [6840/7120 (96%)]	Loss: 0.469293
Train (epoch 28/100) [3720/7120 (52%)]	Loss: 0.459324
Train (epoch 29/100) [600/7120 (8%)]	Loss: 0.459995
Train (epoch 29/100) [4600/7120 (65%)]	Loss: 0.452196
Train (epoch 30/100) [1480/7120 (21%)]	Loss: 0.449662
Train (epoch 30/100) [5480/7120 (77%)]	Loss: 0.452291
Train (epoch 31/100) [2360/7120 (33%)]	Loss: 0.450776
Train (epoch 31/100) [6360/7120 (89%)]	Loss: 0.442134
Train (epoch 32/100) [3240/7120 (46%)]	Loss: 0.442312
Train (epoch 33/100) [120/7120 (2%)]	Loss: 0.438805
Train (epoch 33/100) [4120/7120 (58%)]	Loss: 0.431486
Train (epoch 34/100) [1000/7120 (14%)]	Loss: 0.441259
Train (epoch 34/100) [5000/7120 (70%)]	Loss: 0.438936
Train (epoch 35/100) [1880/7120 (26%)]	Loss: 0.438359
Train (epoch 35/100) [5880/7120 (83%)]	Loss: 0.427079
Train (epoch 36/100) [2760/7120 (39%)]	Loss: 0.430948
Train (epoch 36/100) [6760/7120 (95%)]	Loss: 0.429204
Train (epoch 37/100) [3640/7120 (51%)]	Loss: 0.432297
Train (epoch 38/100) [520/7120 (7%)]	Loss: 0.422850
Train (epoch 38/100) [4520/7120 (63%)]	Loss: 0.430254
Train (epoch 39/100) [1400/7120 (20%)]	Loss: 0.415311
Train (epoch 39/100) [5400/7120 (76%)]	Loss: 0.426656
Train (epoch 40/100) [2280/7120 (32%)]	Loss: 0.421025
Train (epoch 40/100) [6280/7120 (88%)]	Loss: 0.418264
Saving neural network weights in 2021-04-17 16:04:09.251618_epoch40_0.55_gp_4_fq_2_ch_16
Train (epoch 41/100) [3160/7120 (44%)]	Loss: 0.418040
Train (epoch 42/100) [40/7120 (1%)]	Loss: 0.420630
Train (epoch 42/100) [4040/7120 (57%)]	Loss: 0.423352
Train (epoch 43/100) [920/7120 (13%)]	Loss: 0.409665
Train (epoch 43/100) [4920/7120 (69%)]	Loss: 0.417040
Train (epoch 44/100) [1800/7120 (25%)]	Loss: 0.415880
Train (epoch 44/100) [5800/7120 (81%)]	Loss: 0.417432
Train (epoch 45/100) [2680/7120 (38%)]	Loss: 0.404146
Train (epoch 45/100) [6680/7120 (94%)]	Loss: 0.418386
Train (epoch 46/100) [3560/7120 (50%)]	Loss: 0.412018
Train (epoch 47/100) [440/7120 (6%)]	Loss: 0.404199
Train (epoch 47/100) [4440/7120 (62%)]	Loss: 0.408545
Train (epoch 48/100) [1320/7120 (19%)]	Loss: 0.408530
Train (epoch 48/100) [5320/7120 (75%)]	Loss: 0.413841
Train (epoch 49/100) [2200/7120 (31%)]	Loss: 0.406180
Train (epoch 49/100) [6200/7120 (87%)]	Loss: 0.402407
Train (epoch 50/100) [3080/7120 (43%)]	Loss: 0.398874
Train (epoch 50/100) [5133/5162 (99%)]	Loss: 0.413316
Train (epoch 51/100) [3960/7120 (56%)]	Loss: 0.406336
Train (epoch 52/100) [840/7120 (12%)]	Loss: 0.398730
Train (epoch 52/100) [4840/7120 (68%)]	Loss: 0.406142
Train (epoch 53/100) [1720/7120 (24%)]	Loss: 0.401375
Train (epoch 53/100) [5720/7120 (80%)]	Loss: 0.413125
Train (epoch 54/100) [2600/7120 (37%)]	Loss: 0.394250
Train (epoch 54/100) [6600/7120 (93%)]	Loss: 0.400983
Train (epoch 55/100) [3480/7120 (49%)]	Loss: 0.395601
Train (epoch 56/100) [360/7120 (5%)]	Loss: 0.399611
Train (epoch 56/100) [4360/7120 (61%)]	Loss: 0.402610
Train (epoch 57/100) [1240/7120 (17%)]	Loss: 0.396219
Train (epoch 57/100) [5240/7120 (74%)]	Loss: 0.406958
Train (epoch 58/100) [2120/7120 (30%)]	Loss: 0.393126
Train (epoch 58/100) [6120/7120 (86%)]	Loss: 0.403106
Train (epoch 59/100) [3000/7120 (42%)]	Loss: 0.401744
Train (epoch 59/100) [7000/7120 (98%)]	Loss: 0.393215
Train (epoch 60/100) [3880/7120 (54%)]	Loss: 0.390337
Saving neural network weights in 2021-04-17 16:04:37.133854_epoch60_0.58_gp_4_fq_2_ch_16
Train (epoch 61/100) [760/7120 (11%)]	Loss: 0.399660
Train (epoch 61/100) [4760/7120 (67%)]	Loss: 0.396260
Train (epoch 62/100) [1640/7120 (23%)]	Loss: 0.394446
Train (epoch 62/100) [5640/7120 (79%)]	Loss: 0.391027
Train (epoch 63/100) [2520/7120 (35%)]	Loss: 0.406744
Train (epoch 63/100) [6520/7120 (92%)]	Loss: 0.398988
Train (epoch 64/100) [3400/7120 (48%)]	Loss: 0.391848
Train (epoch 65/100) [280/7120 (4%)]	Loss: 0.401947
Train (epoch 65/100) [4280/7120 (60%)]	Loss: 0.388999
Train (epoch 66/100) [1160/7120 (16%)]	Loss: 0.397670
Train (epoch 66/100) [5160/7120 (72%)]	Loss: 0.393603
Train (epoch 67/100) [2040/7120 (29%)]	Loss: 0.392155
Train (epoch 67/100) [6040/7120 (85%)]	Loss: 0.395564
Train (epoch 68/100) [2920/7120 (41%)]	Loss: 0.385021
Train (epoch 68/100) [6920/7120 (97%)]	Loss: 0.397855
Train (epoch 69/100) [3800/7120 (53%)]	Loss: 0.396972
Train (epoch 70/100) [680/7120 (10%)]	Loss: 0.386783
Train (epoch 70/100) [4680/7120 (66%)]	Loss: 0.394885
Train (epoch 71/100) [1560/7120 (22%)]	Loss: 0.383097
Train (epoch 71/100) [5560/7120 (78%)]	Loss: 0.388556
Train (epoch 72/100) [2440/7120 (34%)]	Loss: 0.397692
Train (epoch 72/100) [6440/7120 (90%)]	Loss: 0.386554
Train (epoch 73/100) [3320/7120 (47%)]	Loss: 0.393840
Train (epoch 74/100) [200/7120 (3%)]	Loss: 0.392609
Train (epoch 74/100) [4200/7120 (59%)]	Loss: 0.392094
Train (epoch 75/100) [1080/7120 (15%)]	Loss: 0.381761
Train (epoch 75/100) [5080/7120 (71%)]	Loss: 0.391635
Train (epoch 76/100) [1960/7120 (28%)]	Loss: 0.391108
Train (epoch 76/100) [5960/7120 (84%)]	Loss: 0.391006
Train (epoch 77/100) [2840/7120 (40%)]	Loss: 0.384338
Train (epoch 77/100) [6840/7120 (96%)]	Loss: 0.389573
Train (epoch 78/100) [3720/7120 (52%)]	Loss: 0.390531
Train (epoch 79/100) [600/7120 (8%)]	Loss: 0.389651
Train (epoch 79/100) [4600/7120 (65%)]	Loss: 0.392931
Train (epoch 80/100) [1480/7120 (21%)]	Loss: 0.387876
Train (epoch 80/100) [5480/7120 (77%)]	Loss: 0.390164
Saving neural network weights in 2021-04-17 16:05:05.995979_epoch80_0.59_gp_4_fq_2_ch_16
Train (epoch 81/100) [2360/7120 (33%)]	Loss: 0.384148
Train (epoch 81/100) [6360/7120 (89%)]	Loss: 0.388496
Train (epoch 82/100) [3240/7120 (46%)]	Loss: 0.390763
Train (epoch 83/100) [120/7120 (2%)]	Loss: 0.391724
Train (epoch 83/100) [4120/7120 (58%)]	Loss: 0.388214
Train (epoch 84/100) [1000/7120 (14%)]	Loss: 0.386787
Train (epoch 84/100) [5000/7120 (70%)]	Loss: 0.384618
Train (epoch 85/100) [1880/7120 (26%)]	Loss: 0.385997
Train (epoch 85/100) [5880/7120 (83%)]	Loss: 0.388956
Train (epoch 86/100) [2760/7120 (39%)]	Loss: 0.383335
Train (epoch 86/100) [6760/7120 (95%)]	Loss: 0.393993
Train (epoch 87/100) [3640/7120 (51%)]	Loss: 0.387075
Train (epoch 88/100) [520/7120 (7%)]	Loss: 0.386483
Train (epoch 88/100) [4520/7120 (63%)]	Loss: 0.381104
Train (epoch 89/100) [1400/7120 (20%)]	Loss: 0.384755
Train (epoch 89/100) [5400/7120 (76%)]	Loss: 0.386371
Train (epoch 90/100) [2280/7120 (32%)]	Loss: 0.385228
Train (epoch 90/100) [6280/7120 (88%)]	Loss: 0.387578
Train (epoch 91/100) [3160/7120 (44%)]	Loss: 0.386483
Train (epoch 92/100) [40/7120 (1%)]	Loss: 0.386745
Train (epoch 92/100) [4040/7120 (57%)]	Loss: 0.388127
Train (epoch 93/100) [920/7120 (13%)]	Loss: 0.381284
Train (epoch 93/100) [4920/7120 (69%)]	Loss: 0.383034
Train (epoch 94/100) [1800/7120 (25%)]	Loss: 0.382881
Train (epoch 94/100) [5800/7120 (81%)]	Loss: 0.390738
Train (epoch 95/100) [2680/7120 (38%)]	Loss: 0.392788
Train (epoch 95/100) [6680/7120 (94%)]	Loss: 0.379987
Train (epoch 96/100) [3560/7120 (50%)]	Loss: 0.383406
Train (epoch 97/100) [440/7120 (6%)]	Loss: 0.385902
Train (epoch 97/100) [4440/7120 (62%)]	Loss: 0.384807
Train (epoch 98/100) [1320/7120 (19%)]	Loss: 0.383253
Train (epoch 98/100) [5320/7120 (75%)]	Loss: 0.380990
Train (epoch 99/100) [2200/7120 (31%)]	Loss: 0.384984
Train (epoch 99/100) [6200/7120 (87%)]	Loss: 0.384958
Train (epoch 100/100) [3080/7120 (43%)]	Loss: 0.385522
Train (epoch 100/100) [5133/5162 (99%)]	Loss: 0.383443
Saving neural network weights in 2021-04-17 16:05:35.783301_epoch100_0.56_gp_4_fq_2_ch_16
Confusion matrix :
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   9   0   0   1   0   0   0   0   0]
 [  0   0 103   4   0   0   0   0   0   0  10 165   4   0   0   0   0]
 [ 11   0  38  45   0   0   0   0   0   0   0  65   6   1   0   0   0]
 [  0   0  15   2   7   0   0   0   6   0   0  16   2   0   0   0   0]
 [  7   0   0   0   0   0   4   0  27   0   0   5   1   0  53   0   0]
 [  0   0   0   0   0   5 138   0   1   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   6   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0  96   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   4   0   0   0   0   0   0   0   0   0   0]
 [  6   0   2   7   0   0   2   0   1   0  80  94   1   2   0   0   0]
 [ 13   0  43   7   0   0   2   0   2   0  42 369  13   0   0   0   0]
 [  1   0  30   8   1   0   1   0   0   0  13  53  12   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0  38   0   3   0]
 [  0   0   0   0   0   5   1   0   0   0   0   0   0   0 239   8   0]
 [ 15   0   0   0   0   0  39   0   0   0   0   0   0   0  13  11   0]
 [  0   0   0   0   0   0   0   0   0   0   3   0   0   0   0   0  16]]---
Accuracy : 56.156%
---
F1 scores :
	Undefined: 0.000
	Alfalfa: 0.000
	Corn-notill: 0.398
	Corn-mintill: 0.377
	Corn: 0.250
	Grass-pasture: 0.000
	Grass-trees: 0.819
	Grass-pasture-mowed: 0.000
	Hay-windrowed: 0.787
	Oats: 0.000
	Soybean-notill: 0.466
	Soybean-mintill: 0.586
	Soybean-clean: 0.152
	Wheat: 0.927
	Woods: 0.855
	Buildings-Grass-Trees-Drives: 0.218
	Stone-Steel-Towers: 0.914
---
Kappa: 0.487

