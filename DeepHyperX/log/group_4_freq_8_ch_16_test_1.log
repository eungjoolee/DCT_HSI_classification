Computation on CUDA GPU device 0
Split 200 bands into 4 groups and use 8 frequency
Image has dimensions 145x145 and 32 channels
Using existing train/test split...
7374 samples selected (over 10249)
Running an experiment with the he_customized model run 1/1
Using existing train/val split...
{'dataset': 'IndianPines', 'model': 'he_customized', 'folder': './Datasets/', 'cuda': 0, 'runs': 1, 'training_sample': 0.8, 'sampling_mode': 'fixed', 'train_set': './Datasets/IndianPines/train.mat', 'test_set': './Datasets/IndianPines/test.mat', 'val_set': './Datasets/IndianPines/val.mat', 'epoch': 100, 'lr': 0.01, 'class_balancing': False, 'test_stride': 1, 'flip_augmentation': True, 'radiation_augmentation': False, 'mixture_augmentation': False, 'with_exploration': False, 'band_group': 4, 'use_freq': 8, 'use_kernel': 16, 'band_selection': 0, 'selection_mode': 'random', 't_band_group': 0, 't_use_freq': 1, 't_use_kernel': 16, 'n_classes': 17, 'n_bands': 32, 'ignored_labels': [0], 'device': device(type='cuda', index=0), 'n_kernel': 16, 'weights': tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
       device='cuda:0'), 'patch_size': 7, 'batch_size': 40, 'learning_rate': 0.01, 'scheduler': <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7ff6d34e6350>, 'supervision': 'full', 'center_pixel': True}
Network :
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv3d: 1-1                            [-1, 16, 8, 5, 5]         1,600
├─Conv3d: 1-2                            [-1, 16, 8, 5, 5]         272
├─Conv3d: 1-3                            [-1, 16, 8, 5, 5]         784
├─Conv3d: 1-4                            [-1, 16, 8, 5, 5]         1,296
├─Conv3d: 1-5                            [-1, 16, 8, 5, 5]         1,808
├─Conv3d: 1-6                            [-1, 16, 8, 5, 5]         272
├─Conv3d: 1-7                            [-1, 16, 8, 5, 5]         784
├─Conv3d: 1-8                            [-1, 16, 8, 5, 5]         1,296
├─Conv3d: 1-9                            [-1, 16, 8, 5, 5]         1,808
├─Conv3d: 1-10                           [-1, 16, 6, 4, 4]         3,088
├─Dropout: 1-11                          [-1, 1536]                --
├─Linear: 1-12                           [-1, 17]                  26,129
==========================================================================================
Total params: 39,137
Trainable params: 39,137
Non-trainable params: 0
Total mult-adds (M): 2.28
==========================================================================================
Input size (MB): 0.01
Forward/backward pass size (MB): 0.23
Params size (MB): 0.15
Estimated Total Size (MB): 0.39
==========================================================================================
Train (epoch 1/100) [3960/7120 (56%)]	Loss: 1.601922
Train (epoch 2/100) [840/7120 (12%)]	Loss: 1.197987
Train (epoch 2/100) [4840/7120 (68%)]	Loss: 1.057383
Train (epoch 3/100) [1720/7120 (24%)]	Loss: 0.994956
Train (epoch 3/100) [5720/7120 (80%)]	Loss: 0.955733
Train (epoch 4/100) [2600/7120 (37%)]	Loss: 0.892974
Train (epoch 4/100) [6600/7120 (93%)]	Loss: 0.834351
Train (epoch 5/100) [3480/7120 (49%)]	Loss: 0.820015
Train (epoch 6/100) [360/7120 (5%)]	Loss: 0.757948
Train (epoch 6/100) [4360/7120 (61%)]	Loss: 0.746085
Train (epoch 7/100) [1240/7120 (17%)]	Loss: 0.690759
Train (epoch 7/100) [5240/7120 (74%)]	Loss: 0.696805
Train (epoch 8/100) [2120/7120 (30%)]	Loss: 0.672634
Train (epoch 8/100) [6120/7120 (86%)]	Loss: 0.675224
Train (epoch 9/100) [3000/7120 (42%)]	Loss: 0.645484
Train (epoch 9/100) [7000/7120 (98%)]	Loss: 0.617078
Train (epoch 10/100) [3880/7120 (54%)]	Loss: 0.612206
Train (epoch 11/100) [760/7120 (11%)]	Loss: 0.578809
Train (epoch 11/100) [4760/7120 (67%)]	Loss: 0.573232
Train (epoch 12/100) [1640/7120 (23%)]	Loss: 0.575545
Train (epoch 12/100) [5640/7120 (79%)]	Loss: 0.558087
Train (epoch 13/100) [2520/7120 (35%)]	Loss: 0.533049
Train (epoch 13/100) [6520/7120 (92%)]	Loss: 0.532054
Train (epoch 14/100) [3400/7120 (48%)]	Loss: 0.528557
Train (epoch 15/100) [280/7120 (4%)]	Loss: 0.545912
Train (epoch 15/100) [4280/7120 (60%)]	Loss: 0.505535
Train (epoch 16/100) [1160/7120 (16%)]	Loss: 0.509844
Train (epoch 16/100) [5160/7120 (72%)]	Loss: 0.498214
Train (epoch 17/100) [2040/7120 (29%)]	Loss: 0.500611
Train (epoch 17/100) [6040/7120 (85%)]	Loss: 0.486239
Train (epoch 18/100) [2920/7120 (41%)]	Loss: 0.484858
Train (epoch 18/100) [6920/7120 (97%)]	Loss: 0.474200
Train (epoch 19/100) [3800/7120 (53%)]	Loss: 0.458987
Train (epoch 20/100) [680/7120 (10%)]	Loss: 0.465301
Train (epoch 20/100) [4680/7120 (66%)]	Loss: 0.450144
Saving neural network weights in 2021-04-17 02:11:56.776801_epoch20_0.83_gp_4_fq_8_ch_16
Train (epoch 21/100) [1560/7120 (22%)]	Loss: 0.454977
Train (epoch 21/100) [5560/7120 (78%)]	Loss: 0.444107
Train (epoch 22/100) [2440/7120 (34%)]	Loss: 0.424464
Train (epoch 22/100) [6440/7120 (90%)]	Loss: 0.441773
Train (epoch 23/100) [3320/7120 (47%)]	Loss: 0.427744
Train (epoch 24/100) [200/7120 (3%)]	Loss: 0.448780
Train (epoch 24/100) [4200/7120 (59%)]	Loss: 0.423684
Train (epoch 25/100) [1080/7120 (15%)]	Loss: 0.413445
Train (epoch 25/100) [5080/7120 (71%)]	Loss: 0.413602
Train (epoch 26/100) [1960/7120 (28%)]	Loss: 0.416367
Train (epoch 26/100) [5960/7120 (84%)]	Loss: 0.414648
Train (epoch 27/100) [2840/7120 (40%)]	Loss: 0.414866
Train (epoch 27/100) [6840/7120 (96%)]	Loss: 0.405327
Train (epoch 28/100) [3720/7120 (52%)]	Loss: 0.385297
Train (epoch 29/100) [600/7120 (8%)]	Loss: 0.405161
Train (epoch 29/100) [4600/7120 (65%)]	Loss: 0.392221
Train (epoch 30/100) [1480/7120 (21%)]	Loss: 0.379863
Train (epoch 30/100) [5480/7120 (77%)]	Loss: 0.385418
Train (epoch 31/100) [2360/7120 (33%)]	Loss: 0.383059
Train (epoch 31/100) [6360/7120 (89%)]	Loss: 0.364229
Train (epoch 32/100) [3240/7120 (46%)]	Loss: 0.376860
Train (epoch 33/100) [120/7120 (2%)]	Loss: 0.375925
Train (epoch 33/100) [4120/7120 (58%)]	Loss: 0.359945
Train (epoch 34/100) [1000/7120 (14%)]	Loss: 0.362267
Train (epoch 34/100) [5000/7120 (70%)]	Loss: 0.370673
Train (epoch 35/100) [1880/7120 (26%)]	Loss: 0.358740
Train (epoch 35/100) [5880/7120 (83%)]	Loss: 0.366785
Train (epoch 36/100) [2760/7120 (39%)]	Loss: 0.362300
Train (epoch 36/100) [6760/7120 (95%)]	Loss: 0.340211
Train (epoch 37/100) [3640/7120 (51%)]	Loss: 0.355285
Train (epoch 38/100) [520/7120 (7%)]	Loss: 0.338673
Train (epoch 38/100) [4520/7120 (63%)]	Loss: 0.337711
Train (epoch 39/100) [1400/7120 (20%)]	Loss: 0.350215
Train (epoch 39/100) [5400/7120 (76%)]	Loss: 0.335378
Train (epoch 40/100) [2280/7120 (32%)]	Loss: 0.321146
Train (epoch 40/100) [6280/7120 (88%)]	Loss: 0.348751
Saving neural network weights in 2021-04-17 02:12:12.681533_epoch40_0.84_gp_4_fq_8_ch_16
Train (epoch 41/100) [3160/7120 (44%)]	Loss: 0.329354
Train (epoch 42/100) [40/7120 (1%)]	Loss: 0.337809
Train (epoch 42/100) [4040/7120 (57%)]	Loss: 0.333749
Train (epoch 43/100) [920/7120 (13%)]	Loss: 0.331928
Train (epoch 43/100) [4920/7120 (69%)]	Loss: 0.339582
Train (epoch 44/100) [1800/7120 (25%)]	Loss: 0.319607
Train (epoch 44/100) [5800/7120 (81%)]	Loss: 0.319981
Train (epoch 45/100) [2680/7120 (38%)]	Loss: 0.328347
Train (epoch 45/100) [6680/7120 (94%)]	Loss: 0.328774
Train (epoch 46/100) [3560/7120 (50%)]	Loss: 0.321435
Train (epoch 47/100) [440/7120 (6%)]	Loss: 0.315933
Train (epoch 47/100) [4440/7120 (62%)]	Loss: 0.321021
Train (epoch 48/100) [1320/7120 (19%)]	Loss: 0.310525
Train (epoch 48/100) [5320/7120 (75%)]	Loss: 0.309121
Train (epoch 49/100) [2200/7120 (31%)]	Loss: 0.314586
Train (epoch 49/100) [6200/7120 (87%)]	Loss: 0.308083
Train (epoch 50/100) [3080/7120 (43%)]	Loss: 0.300026
Train (epoch 50/100) [5133/5162 (99%)]	Loss: 0.307641
Train (epoch 51/100) [3960/7120 (56%)]	Loss: 0.306834
Train (epoch 52/100) [840/7120 (12%)]	Loss: 0.299867
Train (epoch 52/100) [4840/7120 (68%)]	Loss: 0.303155
Train (epoch 53/100) [1720/7120 (24%)]	Loss: 0.291565
Train (epoch 53/100) [5720/7120 (80%)]	Loss: 0.303289
Train (epoch 54/100) [2600/7120 (37%)]	Loss: 0.289429
Train (epoch 54/100) [6600/7120 (93%)]	Loss: 0.313566
Train (epoch 55/100) [3480/7120 (49%)]	Loss: 0.295432
Train (epoch 56/100) [360/7120 (5%)]	Loss: 0.301129
Train (epoch 56/100) [4360/7120 (61%)]	Loss: 0.297683
Train (epoch 57/100) [1240/7120 (17%)]	Loss: 0.287809
Train (epoch 57/100) [5240/7120 (74%)]	Loss: 0.299969
Train (epoch 58/100) [2120/7120 (30%)]	Loss: 0.284811
Train (epoch 58/100) [6120/7120 (86%)]	Loss: 0.291413
Train (epoch 59/100) [3000/7120 (42%)]	Loss: 0.290618
Train (epoch 59/100) [7000/7120 (98%)]	Loss: 0.290622
Train (epoch 60/100) [3880/7120 (54%)]	Loss: 0.285185
Saving neural network weights in 2021-04-17 02:12:29.485037_epoch60_0.90_gp_4_fq_8_ch_16
Train (epoch 61/100) [760/7120 (11%)]	Loss: 0.299021
Train (epoch 61/100) [4760/7120 (67%)]	Loss: 0.291846
Train (epoch 62/100) [1640/7120 (23%)]	Loss: 0.280095
Train (epoch 62/100) [5640/7120 (79%)]	Loss: 0.280234
Train (epoch 63/100) [2520/7120 (35%)]	Loss: 0.292338
Train (epoch 63/100) [6520/7120 (92%)]	Loss: 0.273821
Train (epoch 64/100) [3400/7120 (48%)]	Loss: 0.280763
Train (epoch 65/100) [280/7120 (4%)]	Loss: 0.271355
Train (epoch 65/100) [4280/7120 (60%)]	Loss: 0.291145
Train (epoch 66/100) [1160/7120 (16%)]	Loss: 0.273558
Train (epoch 66/100) [5160/7120 (72%)]	Loss: 0.270764
Train (epoch 67/100) [2040/7120 (29%)]	Loss: 0.271421
Train (epoch 67/100) [6040/7120 (85%)]	Loss: 0.268369
Train (epoch 68/100) [2920/7120 (41%)]	Loss: 0.270369
Train (epoch 68/100) [6920/7120 (97%)]	Loss: 0.261292
Train (epoch 69/100) [3800/7120 (53%)]	Loss: 0.266697
Train (epoch 70/100) [680/7120 (10%)]	Loss: 0.276051
Train (epoch 70/100) [4680/7120 (66%)]	Loss: 0.264129
Train (epoch 71/100) [1560/7120 (22%)]	Loss: 0.276255
Train (epoch 71/100) [5560/7120 (78%)]	Loss: 0.262019
Train (epoch 72/100) [2440/7120 (34%)]	Loss: 0.264718
Train (epoch 72/100) [6440/7120 (90%)]	Loss: 0.255981
Train (epoch 73/100) [3320/7120 (47%)]	Loss: 0.270443
Train (epoch 74/100) [200/7120 (3%)]	Loss: 0.265040
Train (epoch 74/100) [4200/7120 (59%)]	Loss: 0.253646
Train (epoch 75/100) [1080/7120 (15%)]	Loss: 0.263295
Train (epoch 75/100) [5080/7120 (71%)]	Loss: 0.265428
Train (epoch 76/100) [1960/7120 (28%)]	Loss: 0.258275
Train (epoch 76/100) [5960/7120 (84%)]	Loss: 0.269929
Train (epoch 77/100) [2840/7120 (40%)]	Loss: 0.257981
Train (epoch 77/100) [6840/7120 (96%)]	Loss: 0.256170
Train (epoch 78/100) [3720/7120 (52%)]	Loss: 0.262727
Train (epoch 79/100) [600/7120 (8%)]	Loss: 0.252460
Train (epoch 79/100) [4600/7120 (65%)]	Loss: 0.256555
Train (epoch 80/100) [1480/7120 (21%)]	Loss: 0.250002
Train (epoch 80/100) [5480/7120 (77%)]	Loss: 0.248959
Saving neural network weights in 2021-04-17 02:12:46.772407_epoch80_0.90_gp_4_fq_8_ch_16
Train (epoch 81/100) [2360/7120 (33%)]	Loss: 0.255314
Train (epoch 81/100) [6360/7120 (89%)]	Loss: 0.251656
Train (epoch 82/100) [3240/7120 (46%)]	Loss: 0.259036
Train (epoch 83/100) [120/7120 (2%)]	Loss: 0.247844
Train (epoch 83/100) [4120/7120 (58%)]	Loss: 0.255424
Train (epoch 84/100) [1000/7120 (14%)]	Loss: 0.244960
Train (epoch 84/100) [5000/7120 (70%)]	Loss: 0.242651
Train (epoch 85/100) [1880/7120 (26%)]	Loss: 0.247670
Train (epoch 85/100) [5880/7120 (83%)]	Loss: 0.248893
Train (epoch 86/100) [2760/7120 (39%)]	Loss: 0.255613
Train (epoch 86/100) [6760/7120 (95%)]	Loss: 0.248627
Train (epoch 87/100) [3640/7120 (51%)]	Loss: 0.243640
Train (epoch 88/100) [520/7120 (7%)]	Loss: 0.250126
Train (epoch 88/100) [4520/7120 (63%)]	Loss: 0.242517
Train (epoch 89/100) [1400/7120 (20%)]	Loss: 0.247606
Train (epoch 89/100) [5400/7120 (76%)]	Loss: 0.247881
Train (epoch 90/100) [2280/7120 (32%)]	Loss: 0.232136
Train (epoch 90/100) [6280/7120 (88%)]	Loss: 0.236365
Train (epoch 91/100) [3160/7120 (44%)]	Loss: 0.249369
Train (epoch 92/100) [40/7120 (1%)]	Loss: 0.246788
Train (epoch 92/100) [4040/7120 (57%)]	Loss: 0.229194
Train (epoch 93/100) [920/7120 (13%)]	Loss: 0.246728
Train (epoch 93/100) [4920/7120 (69%)]	Loss: 0.239741
Train (epoch 94/100) [1800/7120 (25%)]	Loss: 0.242603
Train (epoch 94/100) [5800/7120 (81%)]	Loss: 0.239962
Train (epoch 95/100) [2680/7120 (38%)]	Loss: 0.227542
Train (epoch 95/100) [6680/7120 (94%)]	Loss: 0.237649
Train (epoch 96/100) [3560/7120 (50%)]	Loss: 0.250750
Train (epoch 97/100) [440/7120 (6%)]	Loss: 0.237659
Train (epoch 97/100) [4440/7120 (62%)]	Loss: 0.239249
Train (epoch 98/100) [1320/7120 (19%)]	Loss: 0.238270
Train (epoch 98/100) [5320/7120 (75%)]	Loss: 0.231555
Train (epoch 99/100) [2200/7120 (31%)]	Loss: 0.241884
Train (epoch 99/100) [6200/7120 (87%)]	Loss: 0.240704
Train (epoch 100/100) [3080/7120 (43%)]	Loss: 0.240692
Train (epoch 100/100) [5133/5162 (99%)]	Loss: 0.227414
Saving neural network weights in 2021-04-17 02:13:04.704279_epoch100_0.92_gp_4_fq_8_ch_16
Confusion matrix :
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   8   1   0   0   0   0   0   1   0   0   0   0   0   0   0   0]
 [  0   0 256   0   1   0   0   0   0   0   6  22   1   0   0   0   0]
 [ 11   0   4 135   3   0   0   0   0   0   0  10   3   0   0   0   0]
 [  0   0   0   0  48   0   0   0   0   0   0   0   0   0   0   0   0]
 [  7   0   0   0   0  85   1   0   0   0   0   3   1   0   0   0   0]
 [  0   0   0   0   0   0 145   0   0   0   0   0   0   0   1   0   0]
 [  0   0   0   0   0   2   0   4   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0  96   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   4   0   0   0   0   0   0   0]
 [  6   0   1   0   0   0   0   0   0   0 161  27   0   0   0   0   0]
 [ 13   0   2   2   0   0   0   0   0   0   9 464   1   0   0   0   0]
 [  1   0  13   0   0   0   1   0   0   0   2  12  90   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0  41   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 248   5   0]
 [ 15   0   0   0   0   1   6   0   0   0   0   0   0   0  11  45   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  19]]---
Accuracy : 89.976%
---
F1 scores :
	Undefined: 0.000
	Alfalfa: 0.889
	Corn-notill: 0.909
	Corn-mintill: 0.891
	Corn: 0.960
	Grass-pasture: 0.919
	Grass-trees: 0.970
	Grass-pasture-mowed: 0.800
	Hay-windrowed: 0.995
	Oats: 1.000
	Soybean-notill: 0.863
	Soybean-mintill: 0.902
	Soybean-clean: 0.837
	Wheat: 1.000
	Woods: 0.967
	Buildings-Grass-Trees-Drives: 0.703
	Stone-Steel-Towers: 1.000
---
Kappa: 0.885

