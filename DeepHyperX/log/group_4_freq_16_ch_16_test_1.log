Computation on CUDA GPU device 0
Split 200 bands into 4 groups and use 16 frequency
Image has dimensions 145x145 and 64 channels
Using existing train/test split...
7374 samples selected (over 10249)
Running an experiment with the he_customized model run 1/1
Using existing train/val split...
{'dataset': 'IndianPines', 'model': 'he_customized', 'folder': './Datasets/', 'cuda': 0, 'runs': 1, 'training_sample': 0.8, 'sampling_mode': 'fixed', 'train_set': './Datasets/IndianPines/train.mat', 'test_set': './Datasets/IndianPines/test.mat', 'val_set': './Datasets/IndianPines/val.mat', 'epoch': 100, 'lr': 0.01, 'class_balancing': False, 'test_stride': 1, 'flip_augmentation': True, 'radiation_augmentation': False, 'mixture_augmentation': False, 'with_exploration': False, 'band_group': 4, 'use_freq': 16, 'use_kernel': 16, 'band_selection': 0, 'selection_mode': 'random', 't_band_group': 0, 't_use_freq': 1, 't_use_kernel': 16, 'n_classes': 17, 'n_bands': 64, 'ignored_labels': [0], 'device': device(type='cuda', index=0), 'n_kernel': 16, 'weights': tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
       device='cuda:0'), 'patch_size': 7, 'batch_size': 40, 'learning_rate': 0.01, 'scheduler': <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7fca6c8c1b10>, 'supervision': 'full', 'center_pixel': True}
Network :
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv3d: 1-1                            [-1, 16, 18, 5, 5]        1,600
├─Conv3d: 1-2                            [-1, 16, 18, 5, 5]        272
├─Conv3d: 1-3                            [-1, 16, 18, 5, 5]        784
├─Conv3d: 1-4                            [-1, 16, 18, 5, 5]        1,296
├─Conv3d: 1-5                            [-1, 16, 18, 5, 5]        2,832
├─Conv3d: 1-6                            [-1, 16, 18, 5, 5]        272
├─Conv3d: 1-7                            [-1, 16, 18, 5, 5]        784
├─Conv3d: 1-8                            [-1, 16, 18, 5, 5]        1,296
├─Conv3d: 1-9                            [-1, 16, 18, 5, 5]        2,832
├─Conv3d: 1-10                           [-1, 16, 16, 4, 4]        3,088
├─Dropout: 1-11                          [-1, 4096]                --
├─Linear: 1-12                           [-1, 17]                  69,649
==========================================================================================
Total params: 84,705
Trainable params: 84,705
Non-trainable params: 0
Total mult-adds (M): 6.18
==========================================================================================
Input size (MB): 0.01
Forward/backward pass size (MB): 0.53
Params size (MB): 0.32
Estimated Total Size (MB): 0.86
==========================================================================================
Train (epoch 1/100) [3960/7120 (56%)]	Loss: 1.886101
Train (epoch 2/100) [840/7120 (12%)]	Loss: 1.175494
Train (epoch 2/100) [4840/7120 (68%)]	Loss: 1.085733
Train (epoch 3/100) [1720/7120 (24%)]	Loss: 1.000622
Train (epoch 3/100) [5720/7120 (80%)]	Loss: 0.974079
Train (epoch 4/100) [2600/7120 (37%)]	Loss: 0.946492
Train (epoch 4/100) [6600/7120 (93%)]	Loss: 0.883337
Train (epoch 5/100) [3480/7120 (49%)]	Loss: 0.857805
Train (epoch 6/100) [360/7120 (5%)]	Loss: 0.815842
Train (epoch 6/100) [4360/7120 (61%)]	Loss: 0.803954
Train (epoch 7/100) [1240/7120 (17%)]	Loss: 0.776455
Train (epoch 7/100) [5240/7120 (74%)]	Loss: 0.763396
Train (epoch 8/100) [2120/7120 (30%)]	Loss: 0.765625
Train (epoch 8/100) [6120/7120 (86%)]	Loss: 0.695724
Train (epoch 9/100) [3000/7120 (42%)]	Loss: 0.690675
Train (epoch 9/100) [7000/7120 (98%)]	Loss: 0.691012
Train (epoch 10/100) [3880/7120 (54%)]	Loss: 0.671657
Train (epoch 11/100) [760/7120 (11%)]	Loss: 0.653046
Train (epoch 11/100) [4760/7120 (67%)]	Loss: 0.651647
Train (epoch 12/100) [1640/7120 (23%)]	Loss: 0.633877
Train (epoch 12/100) [5640/7120 (79%)]	Loss: 0.615386
Train (epoch 13/100) [2520/7120 (35%)]	Loss: 0.605697
Train (epoch 13/100) [6520/7120 (92%)]	Loss: 0.601616
Train (epoch 14/100) [3400/7120 (48%)]	Loss: 0.574803
Train (epoch 15/100) [280/7120 (4%)]	Loss: 0.556991
Train (epoch 15/100) [4280/7120 (60%)]	Loss: 0.544206
Train (epoch 16/100) [1160/7120 (16%)]	Loss: 0.546129
Train (epoch 16/100) [5160/7120 (72%)]	Loss: 0.546274
Train (epoch 17/100) [2040/7120 (29%)]	Loss: 0.519008
Train (epoch 17/100) [6040/7120 (85%)]	Loss: 0.520294
Train (epoch 18/100) [2920/7120 (41%)]	Loss: 0.508856
Train (epoch 18/100) [6920/7120 (97%)]	Loss: 0.502837
Train (epoch 19/100) [3800/7120 (53%)]	Loss: 0.499637
Train (epoch 20/100) [680/7120 (10%)]	Loss: 0.493976
Train (epoch 20/100) [4680/7120 (66%)]	Loss: 0.478286
Saving neural network weights in 2021-04-17 02:09:54.872945_epoch20_0.83_gp_4_fq_16_ch_16
Train (epoch 21/100) [1560/7120 (22%)]	Loss: 0.478128
Train (epoch 21/100) [5560/7120 (78%)]	Loss: 0.474603
Train (epoch 22/100) [2440/7120 (34%)]	Loss: 0.432622
Train (epoch 22/100) [6440/7120 (90%)]	Loss: 0.448479
Train (epoch 23/100) [3320/7120 (47%)]	Loss: 0.442888
Train (epoch 24/100) [200/7120 (3%)]	Loss: 0.444201
Train (epoch 24/100) [4200/7120 (59%)]	Loss: 0.429450
Train (epoch 25/100) [1080/7120 (15%)]	Loss: 0.440366
Train (epoch 25/100) [5080/7120 (71%)]	Loss: 0.436369
Train (epoch 26/100) [1960/7120 (28%)]	Loss: 0.412061
Train (epoch 26/100) [5960/7120 (84%)]	Loss: 0.416466
Train (epoch 27/100) [2840/7120 (40%)]	Loss: 0.420136
Train (epoch 27/100) [6840/7120 (96%)]	Loss: 0.410326
Train (epoch 28/100) [3720/7120 (52%)]	Loss: 0.403076
Train (epoch 29/100) [600/7120 (8%)]	Loss: 0.398401
Train (epoch 29/100) [4600/7120 (65%)]	Loss: 0.390660
Train (epoch 30/100) [1480/7120 (21%)]	Loss: 0.394163
Train (epoch 30/100) [5480/7120 (77%)]	Loss: 0.392182
Train (epoch 31/100) [2360/7120 (33%)]	Loss: 0.392953
Train (epoch 31/100) [6360/7120 (89%)]	Loss: 0.367318
Train (epoch 32/100) [3240/7120 (46%)]	Loss: 0.375897
Train (epoch 33/100) [120/7120 (2%)]	Loss: 0.381032
Train (epoch 33/100) [4120/7120 (58%)]	Loss: 0.369451
Train (epoch 34/100) [1000/7120 (14%)]	Loss: 0.375573
Train (epoch 34/100) [5000/7120 (70%)]	Loss: 0.356255
Train (epoch 35/100) [1880/7120 (26%)]	Loss: 0.363082
Train (epoch 35/100) [5880/7120 (83%)]	Loss: 0.354042
Train (epoch 36/100) [2760/7120 (39%)]	Loss: 0.354582
Train (epoch 36/100) [6760/7120 (95%)]	Loss: 0.337539
Train (epoch 37/100) [3640/7120 (51%)]	Loss: 0.356637
Train (epoch 38/100) [520/7120 (7%)]	Loss: 0.337767
Train (epoch 38/100) [4520/7120 (63%)]	Loss: 0.355757
Train (epoch 39/100) [1400/7120 (20%)]	Loss: 0.340730
Train (epoch 39/100) [5400/7120 (76%)]	Loss: 0.345642
Train (epoch 40/100) [2280/7120 (32%)]	Loss: 0.331901
Train (epoch 40/100) [6280/7120 (88%)]	Loss: 0.317330
Saving neural network weights in 2021-04-17 02:10:19.722873_epoch40_0.87_gp_4_fq_16_ch_16
Train (epoch 41/100) [3160/7120 (44%)]	Loss: 0.333092
Train (epoch 42/100) [40/7120 (1%)]	Loss: 0.321262
Train (epoch 42/100) [4040/7120 (57%)]	Loss: 0.329432
Train (epoch 43/100) [920/7120 (13%)]	Loss: 0.322094
Train (epoch 43/100) [4920/7120 (69%)]	Loss: 0.318650
Train (epoch 44/100) [1800/7120 (25%)]	Loss: 0.322297
Train (epoch 44/100) [5800/7120 (81%)]	Loss: 0.321692
Train (epoch 45/100) [2680/7120 (38%)]	Loss: 0.309892
Train (epoch 45/100) [6680/7120 (94%)]	Loss: 0.310121
Train (epoch 46/100) [3560/7120 (50%)]	Loss: 0.312632
Train (epoch 47/100) [440/7120 (6%)]	Loss: 0.316332
Train (epoch 47/100) [4440/7120 (62%)]	Loss: 0.298543
Train (epoch 48/100) [1320/7120 (19%)]	Loss: 0.323787
Train (epoch 48/100) [5320/7120 (75%)]	Loss: 0.289298
Train (epoch 49/100) [2200/7120 (31%)]	Loss: 0.317422
Train (epoch 49/100) [6200/7120 (87%)]	Loss: 0.298694
Train (epoch 50/100) [3080/7120 (43%)]	Loss: 0.304075
Train (epoch 50/100) [5133/5162 (99%)]	Loss: 0.290129
Train (epoch 51/100) [3960/7120 (56%)]	Loss: 0.301666
Train (epoch 52/100) [840/7120 (12%)]	Loss: 0.281744
Train (epoch 52/100) [4840/7120 (68%)]	Loss: 0.283718
Train (epoch 53/100) [1720/7120 (24%)]	Loss: 0.290890
Train (epoch 53/100) [5720/7120 (80%)]	Loss: 0.282254
Train (epoch 54/100) [2600/7120 (37%)]	Loss: 0.295109
Train (epoch 54/100) [6600/7120 (93%)]	Loss: 0.288221
Train (epoch 55/100) [3480/7120 (49%)]	Loss: 0.287347
Train (epoch 56/100) [360/7120 (5%)]	Loss: 0.294104
Train (epoch 56/100) [4360/7120 (61%)]	Loss: 0.276347
Train (epoch 57/100) [1240/7120 (17%)]	Loss: 0.277915
Train (epoch 57/100) [5240/7120 (74%)]	Loss: 0.281008
Train (epoch 58/100) [2120/7120 (30%)]	Loss: 0.272664
Train (epoch 58/100) [6120/7120 (86%)]	Loss: 0.279013
Train (epoch 59/100) [3000/7120 (42%)]	Loss: 0.259607
Train (epoch 59/100) [7000/7120 (98%)]	Loss: 0.281702
Train (epoch 60/100) [3880/7120 (54%)]	Loss: 0.265253
Saving neural network weights in 2021-04-17 02:10:44.909127_epoch60_0.90_gp_4_fq_16_ch_16
Train (epoch 61/100) [760/7120 (11%)]	Loss: 0.268893
Train (epoch 61/100) [4760/7120 (67%)]	Loss: 0.264194
Train (epoch 62/100) [1640/7120 (23%)]	Loss: 0.280797
Train (epoch 62/100) [5640/7120 (79%)]	Loss: 0.270494
Train (epoch 63/100) [2520/7120 (35%)]	Loss: 0.273495
Train (epoch 63/100) [6520/7120 (92%)]	Loss: 0.262557
Train (epoch 64/100) [3400/7120 (48%)]	Loss: 0.262597
Train (epoch 65/100) [280/7120 (4%)]	Loss: 0.247392
Train (epoch 65/100) [4280/7120 (60%)]	Loss: 0.264824
Train (epoch 66/100) [1160/7120 (16%)]	Loss: 0.248322
Train (epoch 66/100) [5160/7120 (72%)]	Loss: 0.262737
Train (epoch 67/100) [2040/7120 (29%)]	Loss: 0.255080
Train (epoch 67/100) [6040/7120 (85%)]	Loss: 0.264435
Train (epoch 68/100) [2920/7120 (41%)]	Loss: 0.255056
Train (epoch 68/100) [6920/7120 (97%)]	Loss: 0.257118
Train (epoch 69/100) [3800/7120 (53%)]	Loss: 0.255536
Train (epoch 70/100) [680/7120 (10%)]	Loss: 0.250800
Train (epoch 70/100) [4680/7120 (66%)]	Loss: 0.253681
Train (epoch 71/100) [1560/7120 (22%)]	Loss: 0.252212
Train (epoch 71/100) [5560/7120 (78%)]	Loss: 0.235545
Train (epoch 72/100) [2440/7120 (34%)]	Loss: 0.253333
Train (epoch 72/100) [6440/7120 (90%)]	Loss: 0.247180
Train (epoch 73/100) [3320/7120 (47%)]	Loss: 0.237105
Train (epoch 74/100) [200/7120 (3%)]	Loss: 0.247718
Train (epoch 74/100) [4200/7120 (59%)]	Loss: 0.250874
Train (epoch 75/100) [1080/7120 (15%)]	Loss: 0.242680
Train (epoch 75/100) [5080/7120 (71%)]	Loss: 0.243138
Train (epoch 76/100) [1960/7120 (28%)]	Loss: 0.221757
Train (epoch 76/100) [5960/7120 (84%)]	Loss: 0.250731
Train (epoch 77/100) [2840/7120 (40%)]	Loss: 0.230519
Train (epoch 77/100) [6840/7120 (96%)]	Loss: 0.245051
Train (epoch 78/100) [3720/7120 (52%)]	Loss: 0.243871
Train (epoch 79/100) [600/7120 (8%)]	Loss: 0.239061
Train (epoch 79/100) [4600/7120 (65%)]	Loss: 0.230689
Train (epoch 80/100) [1480/7120 (21%)]	Loss: 0.235725
Train (epoch 80/100) [5480/7120 (77%)]	Loss: 0.244254
Saving neural network weights in 2021-04-17 02:11:10.862051_epoch80_0.91_gp_4_fq_16_ch_16
Train (epoch 81/100) [2360/7120 (33%)]	Loss: 0.230179
Train (epoch 81/100) [6360/7120 (89%)]	Loss: 0.229153
Train (epoch 82/100) [3240/7120 (46%)]	Loss: 0.247221
Train (epoch 83/100) [120/7120 (2%)]	Loss: 0.225523
Train (epoch 83/100) [4120/7120 (58%)]	Loss: 0.233688
Train (epoch 84/100) [1000/7120 (14%)]	Loss: 0.237716
Train (epoch 84/100) [5000/7120 (70%)]	Loss: 0.241947
Train (epoch 85/100) [1880/7120 (26%)]	Loss: 0.224243
Train (epoch 85/100) [5880/7120 (83%)]	Loss: 0.227424
Train (epoch 86/100) [2760/7120 (39%)]	Loss: 0.204280
Train (epoch 86/100) [6760/7120 (95%)]	Loss: 0.243776
Train (epoch 87/100) [3640/7120 (51%)]	Loss: 0.235741
Train (epoch 88/100) [520/7120 (7%)]	Loss: 0.227971
Train (epoch 88/100) [4520/7120 (63%)]	Loss: 0.221980
Train (epoch 89/100) [1400/7120 (20%)]	Loss: 0.230234
Train (epoch 89/100) [5400/7120 (76%)]	Loss: 0.225112
Train (epoch 90/100) [2280/7120 (32%)]	Loss: 0.209189
Train (epoch 90/100) [6280/7120 (88%)]	Loss: 0.230359
Train (epoch 91/100) [3160/7120 (44%)]	Loss: 0.223341
Train (epoch 92/100) [40/7120 (1%)]	Loss: 0.221075
Train (epoch 92/100) [4040/7120 (57%)]	Loss: 0.214950
Train (epoch 93/100) [920/7120 (13%)]	Loss: 0.224202
Train (epoch 93/100) [4920/7120 (69%)]	Loss: 0.216319
Train (epoch 94/100) [1800/7120 (25%)]	Loss: 0.220517
Train (epoch 94/100) [5800/7120 (81%)]	Loss: 0.218766
Train (epoch 95/100) [2680/7120 (38%)]	Loss: 0.216512
Train (epoch 95/100) [6680/7120 (94%)]	Loss: 0.221511
Train (epoch 96/100) [3560/7120 (50%)]	Loss: 0.218317
Train (epoch 97/100) [440/7120 (6%)]	Loss: 0.211049
Train (epoch 97/100) [4440/7120 (62%)]	Loss: 0.213527
Train (epoch 98/100) [1320/7120 (19%)]	Loss: 0.208842
Train (epoch 98/100) [5320/7120 (75%)]	Loss: 0.223894
Train (epoch 99/100) [2200/7120 (31%)]	Loss: 0.217607
Train (epoch 99/100) [6200/7120 (87%)]	Loss: 0.203542
Train (epoch 100/100) [3080/7120 (43%)]	Loss: 0.207683
Train (epoch 100/100) [5133/5162 (99%)]	Loss: 0.214089
Saving neural network weights in 2021-04-17 02:11:37.320291_epoch100_0.91_gp_4_fq_16_ch_16
Confusion matrix :
[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   8   0   0   0   0   0   0   1   0   0   0   1   0   0   0   0]
 [  0   0 253   2   1   0   0   0   0   0  13  17   0   0   0   0   0]
 [ 11   0   0 143   3   0   0   0   0   0   4   5   0   0   0   0   0]
 [  0   0   0   0  47   0   0   0   0   0   1   0   0   0   0   0   0]
 [  7   0   0   0   0  87   0   0   0   0   1   0   1   0   0   1   0]
 [  0   0   0   0   0   0 145   0   0   0   0   0   0   0   1   0   0]
 [  0   0   0   0   0   2   0   4   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0  96   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   4   0   0   0   0   0   0   0]
 [  6   0   0   0   0   0   0   0   0   0 172  14   3   0   0   0   0]
 [ 13   0   1   0   0   0   0   0   0   0  10 465   2   0   0   0   0]
 [  1   0   0   1   0   0   0   0   0   0   5   7 103   0   0   2   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0  41   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 251   2   0]
 [ 15   0   0   0   0   0   2   0   0   0   0   0   0   0   9  52   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  19]]---
Accuracy : 91.971%
---
F1 scores :
	Undefined: 0.000
	Alfalfa: 0.889
	Corn-notill: 0.937
	Corn-mintill: 0.917
	Corn: 0.949
	Grass-pasture: 0.935
	Grass-trees: 0.990
	Grass-pasture-mowed: 0.800
	Hay-windrowed: 0.995
	Oats: 1.000
	Soybean-notill: 0.858
	Soybean-mintill: 0.931
	Soybean-clean: 0.900
	Wheat: 1.000
	Woods: 0.977
	Buildings-Grass-Trees-Drives: 0.770
	Stone-Steel-Towers: 1.000
---
Kappa: 0.909

